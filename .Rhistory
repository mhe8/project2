confusionMatrix(data = as.numeric(predict_value>0.5), reference = test.news$shares_flag)
test.news$shares_flag
confusionMatrix(data = (predict_value>0.5), reference = test.news$shares_flag)
confusionMatrix(data = as.factor(predict_value>0.5), reference = test.news$shares_flag)
as.factor(predict_value>0.5)
test.news$shares_flag
confusionMatrix(data = as.factor(predict_value>0.5), reference = as.factor(test.news$shares_flag))
library(randomForest)
library(randomForest)
bagFit <- randomForest(shares_flag ~ ., data = train.news, mtry = ncol(train.news) - 1,
ntree = 200, importance = TRUE)
bagPred <- predict(bagFit, newdata = dplyr::select(train.news, -shares_flag))
bagPred
bagPred <- predict(bagFit, newdata = dplyr::select(test.news, -shares_flag))
bagPred
confusionMatrix(data = as.factor(bagPred>0.5), reference = as.factor(test.news$shares_flag))
bagFit
summary(bagFit)
View(pop_1_day)
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
library(readr)
library(tidyverse)
library(MASS)
library(caret)
library(randomForest)
bag_confusionMatrix
bag_confusionMatrix <- confusionMatrix(data = as.factor(bagPred>0.5), reference = as.factor(test.news$shares_flag))
bag_confusionMatrix
glm_confusionMatrix
glm_confusionMatrix <- confusionMatrix(data = as.factor(predict_value>0.5), reference = as.factor(test.news$shares_flag))
glm_confusionMatrix
bagFit <- randomForest(shares_flag ~ ., data = train.news, mtry = ncol(train.news) - 20, ntree = 200, importance = TRUE)
bagFit <- randomForest(shares_flag ~ ., data = train.news, mtry = ncol(train.news) - 1, ntree = 200, importance = TRUE)
bagFit <- randomForest(shares_flag ~ ., data = train.news, mtry = sqrt(ncol(train.news) - 1), ntree = 200, importance = TRUE)
bagFit <- randomForest(as.factor(shares_flag) ~ ., data = train.news, mtry = sqrt(ncol(train.news) - 1), ntree = 200, importance = TRUE)
bagPred <- predict(bagFit, newdata = dplyr::select(test.news, -shares_flag))
bag_confusionMatrix <- confusionMatrix(data = as.factor(bagPred>0.5), reference = as.factor(test.news$shares_flag))
bagPred <- predict(bagFit, newdata = dplyr::select(test.news, -shares_flag))
bagPred
bag_confusionMatrix <- confusionMatrix(data = bagPred, reference = as.factor(test.news$shares_flag))
bag_confusionMatrix
bagFit <- randomForest(as.factor(shares_flag) ~ ., data = train.news, mtry = ncol(train.news) - 1, ntree = 200, importance = TRUE)
bagPred <- predict(bagFit, newdata = dplyr::select(test.news, -shares_flag))
bag_confusionMatrix <- confusionMatrix(data = bagPred, reference = as.factor(test.news$shares_flag))
bag_confusionMatrix
pop_raw$shares_flag <- as.factor(pop_raw$shares>=1400)
pop_raw<-pop_raw %>% subset(select=-c(url, timedelta, is_weekend, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday,weekday_is_sunday, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world, shares))
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
library(readr)
library(tidyverse)
library(MASS)
library(caret)
library(randomForest)
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
pop_raw <- readr::read.csv("OnlineNewsPopularity.csv", header = TRUE)
pop_raw <- tidyverse::read.csv("OnlineNewsPopularity.csv", header = TRUE)
??read.csv
?read.csv
pop_raw <- tidyverse::read.csv("OnlineNewsPopularity.csv", header = TRUE)
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
library(readr)
library(tidyverse)
library(MASS)
library(caret)
library(randomForest)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
# summary of the raw pop data
summary(pop_raw)
# From the summary, we can see there are outliers exist in valriables: n_tokens_content,n_unique_tokens,n_non_stop_words
# n_non_stop_unique_tokens, num_hrefs, num_self_hrefs, num_imgs, num_videos, kw_min_min, kw_max_min, kw_max_avg, kw_avg_avg
# self_reference_min_shares, self_reference_max_shares, self_reference_avg_sharess, shares
# Remove the non predictable variables
pop_raw$news_day <- rep("Sunday", nrow(pop_raw))
pop_raw$news_day[pop_raw$weekday_is_monday==1] <- "Monday"
pop_raw$news_day[pop_raw$weekday_is_tuesday==1] <- "Tuesday"
pop_raw$news_day[pop_raw$weekday_is_wednesday==1] <- "Wednesday"
pop_raw$news_day[pop_raw$weekday_is_thursday==1] <- "Thursday"
pop_raw$news_day[pop_raw$weekday_is_friday==1] <- "Friday"
pop_raw$news_day[pop_raw$weekday_is_saturday==1] <- "Saturday"
pop_raw$news_day <- factor(pop_raw$news_day)
# convert the binary outcomes variables into factors
pop_raw$data_channel <- rep('', nrow(pop_raw))
pop_raw$data_channel[pop_raw$data_channel_is_lifestyle==1] <- "lifestyle"
pop_raw$data_channel[pop_raw$data_channel_is_entertainment==1] <- "entertainment"
pop_raw$data_channel[pop_raw$data_channel_is_bus==1] <- "business"
pop_raw$data_channel[pop_raw$data_channel_is_socmed==1] <- "socmed"
pop_raw$data_channel[pop_raw$data_channel_is_tech==1] <- "tech"
pop_raw$data_channel[pop_raw$data_channel_is_world==1] <- "world"
pop_raw$data_channel <- factor(pop_raw$data_channel)
pop_raw$shares_flag <- as.factor(pop_raw$shares>=1400)
pop_raw<-pop_raw %>% subset(select=-c(url, timedelta, is_weekend, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday,weekday_is_sunday, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world, shares))
# filter out outliers
pop_raw_post <- pop_raw %>% filter( n_tokens_content > 0 & n_unique_tokens >= 0 & n_unique_tokens <=1.0 & n_non_stop_words>=0 & n_non_stop_words<=1.0 & n_non_stop_unique_tokens>=0 & n_non_stop_unique_tokens<=1.0)
pop_1_day <- pop_raw_post %>% filter(news_day == 'Monday') %>% subset(select=-c(news_day))
# Sampling the dataset into 80% : training data and 20% : test data:
set.seed(100)
popNewsTrain <- sample(nrow(pop_1_day),as.integer(nrow(pop_1_day)*0.7))
train.news = pop_1_day[popNewsTrain,]
test.news = pop_1_day[-popNewsTrain,]
# Fit the full model
# So try logistic regression model
full.model <- glm(shares_flag ~ ., data = train.news, family = "binomial")
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both", trace = FALSE)
predict_value <- predict(step.model,test.news,type = "response")
glm_confusionMatrix <- confusionMatrix(data = as.factor(predict_value>0.5), reference = as.factor(test.news$shares_flag))
glm_confusionMatrix
bagFit <- randomForest(shares_flag ~ ., data = train.news, mtry = ncol(train.news) - 1, ntree = 200, importance = TRUE)
bagPred <- predict(bagFit, newdata = dplyr::select(test.news, -shares_flag))
bag_confusionMatrix <- confusionMatrix(data = bagPred, reference = as.factor(test.news$shares_flag))
bag_confusionMatrix
predict_value
View(pop_1_day)
# summary of the raw pop data
summary(pop_1_day)
# summary of the raw pop data
box(pop_1_day)
pop_1_day[,'n_tokens_title']
# summary of the raw pop data
boxplot(pop_1_day[,'n_tokens_title'])
# summary of the raw pop data
boxplot(pop_1_day[,c('n_tokens_title','n_tokens_content')])
# summary of the raw pop data
par(mfrow=c(3,4))
boxplot(pop_1_day[,c('n_tokens_title','n_tokens_content')])
# summary of the raw pop data
par(mfrow=c(3,4))
for (col in c('n_tokens_title','n_tokens_content','num_hrefs', 'num_self_hrefs','num_keywords','kw_avg_min','kw_avg_max','kw_max_avg','kw_avg_avg','self_reference_avg_sharess','LDA_00','global_rate_positive_words','global_rate_negative_words','avg_positive_polarity','avg_negative_polarity')){
boxplot(pop_1_day[,col])
}
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
# Combine the weekday variables into one and set it to factor.
pop_raw$news_day <- rep("Sunday", nrow(pop_raw))
pop_raw$news_day[pop_raw$weekday_is_monday==1] <- "Monday"
pop_raw$news_day[pop_raw$weekday_is_tuesday==1] <- "Tuesday"
pop_raw$news_day[pop_raw$weekday_is_wednesday==1] <- "Wednesday"
pop_raw$news_day[pop_raw$weekday_is_thursday==1] <- "Thursday"
pop_raw$news_day[pop_raw$weekday_is_friday==1] <- "Friday"
pop_raw$news_day[pop_raw$weekday_is_saturday==1] <- "Saturday"
pop_raw$news_day <- factor(pop_raw$news_day)
# Combine the channel variables into one and set it to factor.
pop_raw$data_channel <- rep('', nrow(pop_raw))
pop_raw$data_channel[pop_raw$data_channel_is_lifestyle==1] <- "lifestyle"
pop_raw$data_channel[pop_raw$data_channel_is_entertainment==1] <- "entertainment"
pop_raw$data_channel[pop_raw$data_channel_is_bus==1] <- "business"
pop_raw$data_channel[pop_raw$data_channel_is_socmed==1] <- "socmed"
pop_raw$data_channel[pop_raw$data_channel_is_tech==1] <- "tech"
pop_raw$data_channel[pop_raw$data_channel_is_world==1] <- "world"
pop_raw$data_channel <- factor(pop_raw$data_channel)
pop_raw$shares_flag <- as.factor(pop_raw$shares>=1400)
# Remove the non predictable variables
pop_raw<-pop_raw %>% subset(select=-c(url, timedelta, is_weekend, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday,weekday_is_sunday, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))
# filter out outliers
pop_raw_post <- pop_raw %>% filter( n_tokens_content > 0 & n_unique_tokens >= 0 & n_unique_tokens <=1.0 & n_non_stop_words>=0 & n_non_stop_words<=1.0 & n_non_stop_unique_tokens>=0 & n_non_stop_unique_tokens<=1.0)
pop_1_day <- pop_raw_post %>% filter(news_day == 'Monday') %>% subset(select=-c(news_day))
# summary of the raw pop data
par(mfrow=c(3,4))
kay_variable <- c('n_tokens_title','n_tokens_content','num_hrefs', 'num_self_hrefs','num_keywords','kw_avg_min','kw_avg_max','kw_max_avg','kw_avg_avg','self_reference_avg_sharess','LDA_00','global_rate_positive_words','global_rate_negative_words','avg_positive_polarity','avg_negative_polarity')
for (col in kay_variable){
boxplot(pop_1_day[,col])
}
# summary of the raw pop data
par(mfrow=c(3,5))
kay_variable <- c('n_tokens_title','n_tokens_content','num_hrefs', 'num_self_hrefs','num_keywords','kw_avg_min','kw_avg_max','kw_max_avg','kw_avg_avg','self_reference_avg_sharess','LDA_00','global_rate_positive_words','global_rate_negative_words','avg_positive_polarity','avg_negative_polarity')
for (col in kay_variable){
boxplot(pop_1_day[,col])
}
boxplot(pop_1_day[,col], xlab=col )
for (col in kay_variable){
boxplot(pop_1_day[,col], xlab=col )
}
# summary of the raw pop data
par(mfrow=c(3,5))
kay_variable <- c('n_tokens_title','n_tokens_content','num_hrefs', 'num_self_hrefs','num_keywords','kw_avg_min','kw_avg_max','kw_max_avg','kw_avg_avg','self_reference_avg_sharess','LDA_00','global_rate_positive_words','global_rate_negative_words','avg_positive_polarity','avg_negative_polarity')
for (col in kay_variable){
boxplot(pop_1_day[,col], xlab=col )
}
for (col in kay_variable){
plot(pop_1_day[,shares], pop_1_day[,col], main = paste('shares v.s. ',col))
}
# filter out outliers
pop_raw_post <- pop_raw %>% filter( n_tokens_content > 0 & n_unique_tokens >= 0 & n_unique_tokens <=1.0 & n_non_stop_words>=0 & n_non_stop_words<=1.0 & n_non_stop_unique_tokens>=0 & n_non_stop_unique_tokens<=1.0)
pop_1_day <- pop_raw_post %>% filter(news_day == 'Monday') %>% subset(select=-c(news_day))
for (col in kay_variable){
plot(pop_1_day[,shares], pop_1_day[,col], main = paste('shares v.s. ',col))
}
View(pop_1_day)
for (col in kay_variable){
plot(pop_1_day[,shares], pop_1_day[,col], main = paste('shares v.s. ',col))
}
for (col in kay_variable){
plot(pop_1_day[,shares], pop_1_day[,col], main = paste('shares v.s. ',col))
}
plot(pop_1_day[,'shares'], pop_1_day[,col], main = paste('shares v.s. ',col))
for (col in kay_variable){
plot(pop_1_day[,'shares'], pop_1_day[,col], main = paste('shares v.s. ',col))
}
for (col in kay_variable){
plot(pop_1_day[,col], pop_1_day[,'shares'],  main = paste(col, ' v.s. shares'), xlab = col, ylab = 'share')
}
for (col in c('shares',kay_variable)){
hist(pop_1_day[,col],  main = paste('Histogram for ', col ), xlab = col, ylab = 'share')
}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
library(readr)
library(tidyverse)
library(MASS)
library(caret)
library(randomForest)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
# Combine the weekday variables into one and set it to factor.
pop_raw$news_day <- rep("Sunday", nrow(pop_raw))
pop_raw$news_day[pop_raw$weekday_is_monday==1] <- "Monday"
pop_raw$news_day[pop_raw$weekday_is_tuesday==1] <- "Tuesday"
pop_raw$news_day[pop_raw$weekday_is_wednesday==1] <- "Wednesday"
pop_raw$news_day[pop_raw$weekday_is_thursday==1] <- "Thursday"
pop_raw$news_day[pop_raw$weekday_is_friday==1] <- "Friday"
pop_raw$news_day[pop_raw$weekday_is_saturday==1] <- "Saturday"
pop_raw$news_day <- factor(pop_raw$news_day)
# Combine the channel variables into one and set it to factor.
pop_raw$data_channel <- rep('', nrow(pop_raw))
pop_raw$data_channel[pop_raw$data_channel_is_lifestyle==1] <- "lifestyle"
pop_raw$data_channel[pop_raw$data_channel_is_entertainment==1] <- "entertainment"
pop_raw$data_channel[pop_raw$data_channel_is_bus==1] <- "business"
pop_raw$data_channel[pop_raw$data_channel_is_socmed==1] <- "socmed"
pop_raw$data_channel[pop_raw$data_channel_is_tech==1] <- "tech"
pop_raw$data_channel[pop_raw$data_channel_is_world==1] <- "world"
pop_raw$data_channel <- factor(pop_raw$data_channel)
pop_raw$shares_flag <- as.factor(pop_raw$shares>=1400)
# Remove the non predictable variables
pop_raw<-pop_raw %>% subset(select=-c(url, timedelta, is_weekend, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday,weekday_is_sunday, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))
# filter out outliers
pop_raw_post <- pop_raw %>% filter( n_tokens_content > 0 & n_unique_tokens >= 0 & n_unique_tokens <=1.0 & n_non_stop_words>=0 & n_non_stop_words<=1.0 & n_non_stop_unique_tokens>=0 & n_non_stop_unique_tokens<=1.0)
pop_1_day <- pop_raw_post %>% filter(news_day == 'Monday') %>% subset(select=-c(news_day))
# Sampling the dataset into 80% : training data and 20% : test data:
set.seed(100)
popNewsTrain <- sample(nrow(pop_1_day),as.integer(nrow(pop_1_day)*0.7))
train.news = pop_1_day[popNewsTrain,]
test.news = pop_1_day[-popNewsTrain,]
# summary of the raw pop data
par(mfrow=c(3,5))
kay_variable <- c('n_tokens_title','n_tokens_content','num_hrefs', 'num_self_hrefs','num_keywords','kw_avg_min','kw_avg_max','kw_max_avg','kw_avg_avg','self_reference_avg_sharess','LDA_00','global_rate_positive_words','global_rate_negative_words','avg_positive_polarity','avg_negative_polarity')
for (col in kay_variable){
boxplot(train.news[,col], xlab=col)
}
for (col in kay_variable){
plot(train.news[,col], train.news[,'shares'],  main = paste(col, ' v.s. shares'), xlab = col, ylab = 'share')
}
for (col in c('shares',kay_variable)){
hist(train.news[,col],  main = paste('Histogram for ', col ), xlab = col, ylab = 'share')
}
train.news <- train.news %>% subset(select=-c('shares'))
test.news <- test.news %>% subset(select=-c('shares'))
train.news <- train.news %>% subset(select=-c('shares'))
# Sampling the dataset into 80% : training data and 20% : test data:
set.seed(100)
popNewsTrain <- sample(nrow(pop_1_day),as.integer(nrow(pop_1_day)*0.7))
train.news = pop_1_day[popNewsTrain,]
test.news = pop_1_day[-popNewsTrain,]
train.news <- train.news %>% subset(select=-c('shares'))
View(train.news)
train.news <- train.news %>% subset(select=-c('shares','data_channel'))
train.news <- train.news %>% subset(select=- c('shares'))
train.news <- train.news %>% subset(select=-c(shares))
test.news <- test.news %>% subset(select=-c(shares))
# Fit the full model
# So try logistic regression model
full.model <- glm(shares_flag ~ ., data = train.news, family = "binomial")
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both", trace = FALSE)
knit_with_parameters('~/Documents/NCSU_MinHe/ST558/Project2/Project2.Rmd')
knit_with_parameters('~/Documents/NCSU_MinHe/ST558/Project2/Project2.Rmd')
knit_with_parameters('~/Documents/NCSU_MinHe/ST558/Project2/Project2.Rmd')
knit_with_parameters('~/Documents/NCSU_MinHe/ST558/Project2/Project2.Rmd')
knit_with_parameters('~/Documents/NCSU_MinHe/ST558/Project2/Project2.Rmd')
#get unique teams
teamIDs <- unique(pop_raw$news_day)
#get unique teams
days <- unique(pop_raw$news_day)
#get unique days
days <- unique(pop_raw$news_day)
for(d in days){
#create filenames
output_file <- paste0('Project_2_', d, ".md")
#create a list for each team with just the team name parameter
params = lapply(teamIDs, FUN = function(x){list(team = x)})
rmarkdown::render("Project2.Rmd", output_file = output_file, params = list(weekday = d))
}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
library(readr)
library(tidyverse)
library(MASS)
library(caret)
library(randomForest)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
# Combine the weekday variables into one and set it to factor.
pop_raw$news_day <- rep("Sunday", nrow(pop_raw))
pop_raw$news_day[pop_raw$weekday_is_monday==1] <- "Monday"
pop_raw$news_day[pop_raw$weekday_is_tuesday==1] <- "Tuesday"
pop_raw$news_day[pop_raw$weekday_is_wednesday==1] <- "Wednesday"
pop_raw$news_day[pop_raw$weekday_is_thursday==1] <- "Thursday"
pop_raw$news_day[pop_raw$weekday_is_friday==1] <- "Friday"
pop_raw$news_day[pop_raw$weekday_is_saturday==1] <- "Saturday"
pop_raw$news_day <- factor(pop_raw$news_day)
# Combine the channel variables into one and set it to factor.
pop_raw$data_channel <- rep('', nrow(pop_raw))
pop_raw$data_channel[pop_raw$data_channel_is_lifestyle==1] <- "lifestyle"
pop_raw$data_channel[pop_raw$data_channel_is_entertainment==1] <- "entertainment"
pop_raw$data_channel[pop_raw$data_channel_is_bus==1] <- "business"
pop_raw$data_channel[pop_raw$data_channel_is_socmed==1] <- "socmed"
pop_raw$data_channel[pop_raw$data_channel_is_tech==1] <- "tech"
pop_raw$data_channel[pop_raw$data_channel_is_world==1] <- "world"
pop_raw$data_channel <- factor(pop_raw$data_channel)
pop_raw$shares_flag <- as.factor(pop_raw$shares>=1400)
# Remove the non predictable variables
pop_raw<-pop_raw %>% subset(select=-c(url, timedelta, is_weekend, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday,weekday_is_sunday, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))
# filter out outliers
pop_raw_post <- pop_raw %>% filter( n_tokens_content > 0 & n_unique_tokens >= 0 & n_unique_tokens <=1.0 & n_non_stop_words>=0 & n_non_stop_words<=1.0 & n_non_stop_unique_tokens>=0 & n_non_stop_unique_tokens<=1.0)
pop_1_day <- pop_raw_post %>% filter(news_day == paras$weekday) %>% subset(select=-c(news_day))
# Remove the non predictable variables
pop_raw<-pop_raw %>% subset(select=-c(url, timedelta, is_weekend, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday,weekday_is_sunday, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
# Combine the weekday variables into one and set it to factor.
pop_raw$news_day <- rep("Sunday", nrow(pop_raw))
pop_raw$news_day[pop_raw$weekday_is_monday==1] <- "Monday"
pop_raw$news_day[pop_raw$weekday_is_tuesday==1] <- "Tuesday"
pop_raw$news_day[pop_raw$weekday_is_wednesday==1] <- "Wednesday"
pop_raw$news_day[pop_raw$weekday_is_thursday==1] <- "Thursday"
pop_raw$news_day[pop_raw$weekday_is_friday==1] <- "Friday"
pop_raw$news_day[pop_raw$weekday_is_saturday==1] <- "Saturday"
pop_raw$news_day <- factor(pop_raw$news_day)
# Combine the channel variables into one and set it to factor.
pop_raw$data_channel <- rep('', nrow(pop_raw))
pop_raw$data_channel[pop_raw$data_channel_is_lifestyle==1] <- "lifestyle"
pop_raw$data_channel[pop_raw$data_channel_is_entertainment==1] <- "entertainment"
pop_raw$data_channel[pop_raw$data_channel_is_bus==1] <- "business"
pop_raw$data_channel[pop_raw$data_channel_is_socmed==1] <- "socmed"
pop_raw$data_channel[pop_raw$data_channel_is_tech==1] <- "tech"
pop_raw$data_channel[pop_raw$data_channel_is_world==1] <- "world"
pop_raw$data_channel <- factor(pop_raw$data_channel)
pop_raw$shares_flag <- as.factor(pop_raw$shares>=1400)
# Remove the non predictable variables
pop_raw<-pop_raw %>% subset(select=-c(url, timedelta, is_weekend, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday,weekday_is_sunday, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))
# filter out outliers
pop_raw_post <- pop_raw %>% filter( n_tokens_content > 0 & n_unique_tokens >= 0 & n_unique_tokens <=1.0 & n_non_stop_words>=0 & n_non_stop_words<=1.0 & n_non_stop_unique_tokens>=0 & n_non_stop_unique_tokens<=1.0)
pop_1_day <- pop_raw_post %>% filter(news_day == paras$weekday) %>% subset(select=-c(news_day))
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
library(readr)
library(tidyverse)
library(MASS)
library(caret)
library(randomForest)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
# Combine the weekday variables into one and set it to factor.
pop_raw$news_day <- rep("Sunday", nrow(pop_raw))
pop_raw$news_day[pop_raw$weekday_is_monday==1] <- "Monday"
pop_raw$news_day[pop_raw$weekday_is_tuesday==1] <- "Tuesday"
pop_raw$news_day[pop_raw$weekday_is_wednesday==1] <- "Wednesday"
pop_raw$news_day[pop_raw$weekday_is_thursday==1] <- "Thursday"
pop_raw$news_day[pop_raw$weekday_is_friday==1] <- "Friday"
pop_raw$news_day[pop_raw$weekday_is_saturday==1] <- "Saturday"
pop_raw$news_day <- factor(pop_raw$news_day)
# Combine the channel variables into one and set it to factor.
pop_raw$data_channel <- rep('', nrow(pop_raw))
pop_raw$data_channel[pop_raw$data_channel_is_lifestyle==1] <- "lifestyle"
pop_raw$data_channel[pop_raw$data_channel_is_entertainment==1] <- "entertainment"
pop_raw$data_channel[pop_raw$data_channel_is_bus==1] <- "business"
pop_raw$data_channel[pop_raw$data_channel_is_socmed==1] <- "socmed"
pop_raw$data_channel[pop_raw$data_channel_is_tech==1] <- "tech"
pop_raw$data_channel[pop_raw$data_channel_is_world==1] <- "world"
pop_raw$data_channel <- factor(pop_raw$data_channel)
pop_raw$shares_flag <- as.factor(pop_raw$shares>=1400)
# Remove the non predictable variables
pop_raw<-pop_raw %>% subset(select=-c(url, timedelta, is_weekend, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday,weekday_is_sunday, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))
# filter out outliers
pop_raw_post <- pop_raw %>% filter( n_tokens_content > 0 & n_unique_tokens >= 0 & n_unique_tokens <=1.0 & n_non_stop_words>=0 & n_non_stop_words<=1.0 & n_non_stop_unique_tokens>=0 & n_non_stop_unique_tokens<=1.0)
pop_1_day <- pop_raw_post %>% filter(news_day == paras$weekday) %>% subset(select=-c(news_day))
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
library(readr)
library(tidyverse)
library(MASS)
library(caret)
library(randomForest)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
# Combine the weekday variables into one and set it to factor.
pop_raw$news_day <- rep("Sunday", nrow(pop_raw))
pop_raw$news_day[pop_raw$weekday_is_monday==1] <- "Monday"
pop_raw$news_day[pop_raw$weekday_is_tuesday==1] <- "Tuesday"
pop_raw$news_day[pop_raw$weekday_is_wednesday==1] <- "Wednesday"
pop_raw$news_day[pop_raw$weekday_is_thursday==1] <- "Thursday"
pop_raw$news_day[pop_raw$weekday_is_friday==1] <- "Friday"
pop_raw$news_day[pop_raw$weekday_is_saturday==1] <- "Saturday"
pop_raw$news_day <- factor(pop_raw$news_day)
# Combine the channel variables into one and set it to factor.
pop_raw$data_channel <- rep('', nrow(pop_raw))
pop_raw$data_channel[pop_raw$data_channel_is_lifestyle==1] <- "lifestyle"
pop_raw$data_channel[pop_raw$data_channel_is_entertainment==1] <- "entertainment"
pop_raw$data_channel[pop_raw$data_channel_is_bus==1] <- "business"
pop_raw$data_channel[pop_raw$data_channel_is_socmed==1] <- "socmed"
pop_raw$data_channel[pop_raw$data_channel_is_tech==1] <- "tech"
pop_raw$data_channel[pop_raw$data_channel_is_world==1] <- "world"
pop_raw$data_channel <- factor(pop_raw$data_channel)
pop_raw$shares_flag <- as.factor(pop_raw$shares>=1400)
# Remove the non predictable variables
pop_raw<-pop_raw %>% subset(select=-c(url, timedelta, is_weekend, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday,weekday_is_sunday, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world))
# filter out outliers
pop_raw_post <- pop_raw %>% filter( n_tokens_content > 0 & n_unique_tokens >= 0 & n_unique_tokens <=1.0 & n_non_stop_words>=0 & n_non_stop_words<=1.0 & n_non_stop_unique_tokens>=0 & n_non_stop_unique_tokens<=1.0)
pop_1_day <- pop_raw_post %>% filter(news_day == params$weekday) %>% subset(select=-c(news_day))
# Sampling the dataset into 80% : training data and 20% : test data:
set.seed(100)
popNewsTrain <- sample(nrow(pop_1_day),as.integer(nrow(pop_1_day)*0.7))
train.news = pop_1_day[popNewsTrain,]
test.news = pop_1_day[-popNewsTrain,]
# summary of the raw pop data
par(mfrow=c(3,5))
kay_variable <- c('n_tokens_title','n_tokens_content','num_hrefs', 'num_self_hrefs','num_keywords','kw_avg_min','kw_avg_max','kw_max_avg','kw_avg_avg','self_reference_avg_sharess','LDA_00','global_rate_positive_words','global_rate_negative_words','avg_positive_polarity','avg_negative_polarity')
for (col in kay_variable){
boxplot(train.news[,col], xlab=col)
}
par(mfrow=c(3,5))
for (col in kay_variable){
plot(train.news[,col], train.news[,'shares'],  main = paste(col, ' v.s. shares'), xlab = col, ylab = 'shares')
}
par(mfrow=c(3,5))
for (col in c('shares',kay_variable)){
hist(train.news[,col],  main = paste('Histogram for ', col ), xlab = col, ylab = 'share')
}
train.news <- train.news %>% subset(select=-c(shares))
test.news <- test.news %>% subset(select=-c(shares))
# Fit the full model
# So try logistic regression model
full.model <- glm(shares_flag ~ ., data = train.news, family = "binomial")
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both", trace = FALSE)
predict_value <- predict(step.model,test.news,type = "response")
glm_confusionMatrix <- confusionMatrix(data = as.factor(predict_value>0.5), reference = as.factor(test.news$shares_flag))
glm_confusionMatrix
bagFit <- randomForest(shares_flag ~ ., data = train.news, mtry = ncol(train.news) - 1, ntree = 200, importance = TRUE)
bagPred <- predict(bagFit, newdata = dplyr::select(test.news, -shares_flag))
bag_confusionMatrix <- confusionMatrix(data = bagPred, reference = as.factor(test.news$shares_flag))
bag_confusionMatrix
days <- unique(pop_raw$news_day)
for(d in days){
#create filenames
output_file <- paste0('Project_2_', d, ".md")
#create a list for each team with just the team name parameter
params = lapply(teamIDs, FUN = function(x){list(team = x)})
rmarkdown::render("Project2.Rmd", output_file = output_file, params = list(weekday = d))
}
days <- unique(pop_raw$news_day)
for(d in days){
#create filenames
output_file <- paste0('Project_2_', d, ".md")
#create a list for each team with just the team name parameter
rmarkdown::render("Project2.Rmd", output_file = output_file, params = list(weekday = d))
}
days <- unique(pop_raw$news_day)
for(d in days){
#create filenames
output_file <- paste0('Project_2_', d, ".html")
#create a list for each team with just the team name parameter
rmarkdown::render("Project2.Rmd", output_file = output_file, params = list(weekday = d))
}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
#get unique days
days <-  c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday")
for(d in days){
#create filenames
output_file <- paste0('Project_2_', d, ".html")
#create a list for each team with just the team name parameter
rmarkdown::render("Project2.Rmd", output_file = output_file, params = list(weekday = d))
}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
library(readr)
library(tidyverse)
library(MASS)
library(caret)
library(randomForest)
# knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE)
library(readr)
library(tidyverse)
library(MASS)
library(caret)
library(randomForest)
setwd("/home/aaron/Documents/NCSU_MinHe/ST558/project2_question")
pop_raw <- read.csv("OnlineNewsPopularity.csv", header = TRUE)
days <-  c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday")
output_file <- paste0(days,"Analysis.md")
params = lapply(days,FUN = function(x){list(weekday = x)})
reports <- tibble(output_file,params)
apply(reports, MARGIN =1,FUN = function(x){rmarkdown::render(input="Project2.Rmd",output_file=x[[1]],params=x[[2]])})
params
source('~/.active-rstudio-document', echo=TRUE)
library(rmarkdown)
